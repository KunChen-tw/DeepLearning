{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAByRhRiy4cIJckX/YfG7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunChen-tw/DeepLearning/blob/main/deeplearning1019_Ch4_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deconvolution 的練習"
      ],
      "metadata": {
        "id": "qs_NoUmlsV4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdpsE-bxsIWw",
        "outputId": "cc48e8ca-9776-44c7-b8b8-bff8c8e9af3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input feature map:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Kernel:\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Output feature map after transposed convolution:\n",
            "tensor([[1., 0., 2., 0.],\n",
            "        [0., 1., 0., 2.],\n",
            "        [3., 0., 4., 0.],\n",
            "        [0., 3., 0., 4.]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a 2x2 input feature map\n",
        "input_tensor = torch.tensor([[1, 2],\n",
        "               [3, 4]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "# Shape after unsqueeze: (1, 1, 2, 2) to fit PyTorch's expected (batch_size, channels, height, width)\n",
        "\n",
        "# Define a transposed convolution layer with a 2x2 kernel, stride 2, and no bias\n",
        "deconv = nn.ConvTranspose2d(\n",
        "    in_channels=1,      # Number of input channels\n",
        "    out_channels=1,     # Number of output channels\n",
        "    kernel_size=2,      # Size of the convolutional kernel\n",
        "    stride=2,           # Stride value to expand the output size\n",
        "    bias=False          # Disable bias term\n",
        ")\n",
        "\n",
        "# Manually set the weight of the transposed convolution kernel to a simple pattern\n",
        "with torch.no_grad():\n",
        "    deconv.weight = nn.Parameter(torch.tensor([[[[1, 0],\n",
        "                                                 [0, 1]]]], dtype=torch.float32))\n",
        "\n",
        "# Perform forward propagation through the transposed convolution layer\n",
        "output_tensor = deconv(input_tensor)\n",
        "\n",
        "# Print input and output details\n",
        "print(\"Original input feature map:\")\n",
        "print(input_tensor[0][0])\n",
        "\n",
        "print(\"Kernel:\")\n",
        "print(deconv.weight[0][0])\n",
        "\n",
        "print(\"\\nOutput feature map after transposed convolution:\")\n",
        "print(output_tensor[0][0])\n"
      ]
    }
  ]
}